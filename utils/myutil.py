import copy
import numpy as np
from math import fabs, ceil, floor
import torch
import os
from torch.nn import ZeroPad2d
from parse_config import ConfigParser
from utils.default_config import default_config


def skip_concat(x1, x2):
    return torch.cat([x1, x2], dim=1)


def skip_sum(x1, x2):
    return x1 + x2


def mean(l):
    return 0 if len(l) == 0 else sum(l) / len(l)


def quick_norm(img):
    return (img - torch.min(img))/(torch.max(img) - torch.min(img) + 1e-5)


def robust_min(img, p=5):
    return np.percentile(img.ravel(), p)


def robust_max(img, p=95):
    return np.percentile(img.ravel(), p)


def normalize(img, m=10, M=90):
    return np.clip((img - robust_min(img, m)) / (robust_max(img, M) - robust_min(img, m)), 0.0, 1.0)


def ffmpeg_glob_cmd(input_folder, output_path=None):
    if output_path is None:
        output_path = os.path.join(input_folder, 'a_video.mp4')
    return ['ffmpeg', '-y', '-pattern_type', 'glob', '-i',
            os.path.join(input_folder, '*.png'), '-framerate', '20',
            output_path]


def optimal_crop_size(max_size, max_subsample_factor, safety_margin=0):
    """ Find the optimal crop size for a given max_size and subsample_factor.
        The optimal crop size is the smallest integer which is greater or equal than max_size,
        while being divisible by 2^max_subsample_factor.
    """
    crop_size = int(pow(2, max_subsample_factor) * ceil(max_size / pow(2, max_subsample_factor)))
    crop_size += safety_margin * pow(2, max_subsample_factor)
    return crop_size


class CropParameters:
    """ Helper class to compute and store useful parameters for pre-processing and post-processing
        of images in and out of E2VID.
        Pre-processing: finding the best image size for the network, and padding the input image with zeros
        Post-processing: Crop the output image back to the original image size
    """

    def __init__(self, width, height, num_encoders, safety_margin=0):

        self.height = height
        self.width = width
        self.num_encoders = num_encoders
        self.width_crop_size = optimal_crop_size(self.width, num_encoders, safety_margin)
        self.height_crop_size = optimal_crop_size(self.height, num_encoders, safety_margin)

        self.padding_top = ceil(0.5 * (self.height_crop_size - self.height))
        self.padding_bottom = floor(0.5 * (self.height_crop_size - self.height))
        self.padding_left = ceil(0.5 * (self.width_crop_size - self.width))
        self.padding_right = floor(0.5 * (self.width_crop_size - self.width))
        self.pad = ZeroPad2d((self.padding_left, self.padding_right, self.padding_top, self.padding_bottom))

        self.cx = floor(self.width_crop_size / 2)
        self.cy = floor(self.height_crop_size / 2)

        self.ix0 = self.cx - floor(self.width / 2)
        self.ix1 = self.cx + ceil(self.width / 2)
        self.iy0 = self.cy - floor(self.height / 2)
        self.iy1 = self.cy + ceil(self.height / 2)

    def crop(self, img):
        return img[..., self.iy0:self.iy1, self.ix0:self.ix1]


def format_power(size):
    power = 1e3
    n = 0
    power_labels = {0 : '', 1: 'K', 2: 'M', 3: 'G', 4: 'T'}
    while size > power:
        size /= power
        n += 1
    return size, power_labels[n]

def make_henri_compatible(checkpoint):
    """
    Checkpoints have ConfigParser type configs, whereas Henri checkpoints have
    dictionary type configs or "arch, model" dicts.
    We will generate and add a ConfigParser to the checkpoint and return it.
    """
    assert ('config' in checkpoint or ('arch' in checkpoint and 'model' in checkpoint))
    check_config = checkpoint['config'] if 'config' in checkpoint else checkpoint
    new_config = copy.deepcopy(default_config)
    new_config['arch']['type'] = check_config['arch']
    new_config['arch']['args']['unet_kwargs'] = check_config['model']
    config = ConfigParser(new_config)
    checkpoint['config'] = config
    print(new_config)
    return checkpoint


def recursive_clone(tensor):
    """
    Assumes tensor is a torch.tensor with 'clone()' method, possibly
    inside nested iterable.
    E.g., tensor = [(pytorch_tensor, pytorch_tensor), ...]
    """
    if hasattr(tensor, 'clone'):
        return tensor.clone()
    try:
        return type(tensor)(recursive_clone(t) for t in tensor)
    except TypeError:
        print('{} is not iterable and has no clone() method.'.format(tensor))
